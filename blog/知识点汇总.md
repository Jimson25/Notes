# 知识点汇总

## 计算机基础

### 计算机网络

#### OSI参考模型

| 层次       | 协议              | 传输数据   | 功能                                                 |
| ---------- | ----------------- | ---------- | ---------------------------------------------------- |
| 应用层     | HTTP、FTP、SMTP等 | 报文       | 网络的顶层实现                                       |
| 表示层     | \                 | 表示出报文 | 数据传输之前，实现数据的加密、压缩和转换。           |
| 会话层     | \                 | 会话层报文 | 负责建立、管理和终止会话。                           |
| 传输层     | TCP、UDP          | 段         | 提供端到端的通信控制，确保数据的正确性和有效性。     |
| 网络层     | IP、ICMP          | 包         | 负责数据包从源到目的地的路由和转发。                 |
| 数据链路层 | ARP、IEEE 802.11  | 帧         | 在相邻节点之间的可靠传输，处理错误检测和修正。       |
| 物理层     | \                 | 比特流     | 传输原始比特流，涉及电气特性、机械特性、功能特性等。 |

#### 五层参考模型

| 层次       | 协议              | 传输数据 | 功能                                                                                 |
| ---------- | ----------------- | -------- | ------------------------------------------------------------------------------------ |
| 应用层     | HTTP、FTP、SMTP等 | 报文     | 为应用程序提供网络服务，处理特定的应用程序细节。                                     |
| 传输层     | TCP、UDP          | 段       | 提供端到端的通信服务，确保数据的正确性和有效性，<br />包括流量控制、错误检测和纠正。 |
| 网络层     | IP、ICMP          | 包       | 负责数据包从源到目的地的路由和转发，实现不同网络之间的通信。                         |
| 数据链路层 | ARP、IEEE 802.11  | 帧       | 在相邻节点之间的可靠传输，处理错误检测和修正，以及帧的传输。                         |
| 物理层     |                   | 比特流   | 在相邻节点之间的可靠传输，处理错误检测和修正，以及帧的传输。                         |

#### TCP/UDP区别

##### 连接性

- TCP是面向连接的。每次传输数据之前需要先建立连接，在传输完数据之后需要关闭连接。建立连接的过程称为 `三次握手`。

  - 客户端向服务端发送连接建立请求SYN，同时给出客户端的初始序列号。
  - 服务端收到客户端给出的连接建立请求之后，如果此时可以建立连接，则回复SYN-ACK，并给出服务端的序列号。
  - 客户端收到服务端的SYN-ACK之后，回复改请求的ACK，并将初始服务端序号+1，表示收到改数据并成功处理。

  在断开连接时，需要服务端与客户端之间相互确认，这个过程称为 `四次挥手`

  - 客户端在完成数据传输之后，会向服务端发送一个包含FIN位的结束段。
  - 服务端收到FIN报文段之后，会将客户端报文序号+1给出ACK报文。此时，客户端-服务端的连接关闭，但是服务端 - 客户端的连接依然存在，即服务端可以继续向客户端发送数据。这时候的连接称为半关状态。
  - 当服务端完成数据传输之后，会向客户端发送一个包含FIN位的报文段。
  - 客户端收到服务端的FIN报文段之后，将服务端报文序号+1并发送ACK报文。此时服务端 - 客户端的连接被关闭，TCP连接关闭。
- UDP是无连接的，在发送数据之前不需要建立连接。每次发送数据时，只需要将数据包发送到对方即可，不需要关注是否发送成功。

##### 可靠性

- TCP提供可靠的服务。它通过序列号、确认应答、重传机制、流量控制和拥塞控制等机制确保数据包的可靠传输。
- UDP提供不可靠的服务。它不保证数据包的顺序、完整性或可靠性，也不会进行重传。如果需要可靠性，应用程序需要在UDP的基础上自己实现。

##### 传输速度

- TCP是面向连接的，每次传输数据之前需要对连接信息做检查，因此速度较慢。
- UDP不需要面向连接保证可靠传输，因此传输速度较快。

##### 错误检查

- TCP使用校验和来检查数据在传输过程中的完整性，如果发现错误，TCP会重新传输损坏的数据包。
- UDP也使用校验和来检查数据的完整性，但如果发现错误，UDP会简单地将损坏的数据包丢弃，不会进行重传。

##### 流量控制

- TCP具有流量控制机制，通过滑动窗口算法来控制数据的传输速率，以避免网络拥塞。
- UDP没有流量控制机制，应用程序必须自己控制发送速率，以避免发送过快导致网络拥塞。

### 数据结构

#### 链表特点

#### 栈与队列

#### 二叉树

#### 红黑树

#### B树、B+树

#### 哈夫曼树

##### 哈夫曼树的构造

假设有n个权值，则构造出的哈夫曼树有n个叶子结点。 n个权值分别设为 w1、w2、…、wn，则哈夫曼树的构造规则为：

1. 将w1、w2、…，wn看成是有n 棵树的森林(每棵树仅有一个结点)；
2. 在森林中选出两个根结点的权值最小的树合并，作为一棵新树的左、右子树，且新树的根结点权值为其左、右子树根结点权值之和；
3. 从森林中删除选取的两棵树，并将新树加入森林；
4. 重复(2)、(3)步，直到森林中只剩一棵树为止，该树即为所求得的哈夫曼树。

#### 选择排序

#### 冒泡排序

#### 二分法查找

### 操作系统

#### 进程死锁

#### 银行家算法

## JAVA SE

### 初级

#### 集合

##### List、Set、Map之间的区别

* `List`: 存储的元素是有序的、可重复的。
* `Set`: 存储的元素不可重复的。
* `Map`: 使用键值对（key-value）存储，key 是无序的、不可重复的，value 是无序的、可重复的，每个键最多映射到一个值。

##### ArrayList和LinkedList在性能上有什么区别？

- `ArrayList`: 基于数组实现，随机访问性能更好。可以基于 `对象内存地址+元素下标*元素类型占用的内存大小` 直接计算出元素的内存地址，因此查询速度快。但是对于新增和删除，由于在内存中是顺序表结构，因此需要调整后续所有元素的内存地址。
- `LinkedList`：基于双向链表实现，顺序访问性能更好。写入和删除上只需要修改要插入的位置的节点的内存地址变量（地址指针）即可完成插入和删除。而对于查找元素，链表需要从头到尾依次遍历链表中的节点，直到找到所需的元素为止。

##### 能不能在for循环遍历中删除list中的元素？

不能，遍历时删除元素会抛出 `java.lang.UnsupportedOperationException`异常。

##### 如何在遍历List时安全地删除元素？

- 可以使用迭代器中的remove()方法删除。

```java
Iterator<Integer> iterator = list.iterator();
while (iterator.hasNext()) {
    Integer value = iterator.next();
    if (value % 2 == 0) {
        iterator.remove();
    }
}

```

- 可以使用list提供的 `removeIf()` 实现删除，底层还是基于迭代器删除。

##### 如何在List中实现排序？怎么实现自定义排序规则？

- 可以使用 `Collections.sort(list)` 或 `list.sort()` 实现对list的排序。在1.8之后推荐使用后者。
- 要实现自定义排序规则，可以在调用 `sort()`方法时传入一个 `Comparator `类型的对象，重写其中的 `compare()`方法实现自定义排序规则。compare方法接受两个要比较的参数，并根据你的自定义规则返回一个整数值，该值可以是负数、零或正数，分别表示第一个参数小于、等于或大于第二个参数。
- 除了传入一个实现 `Comparator` 接口的对象之外，还可以通过方法引用传入一个用于比较的静态方法。这个方法所属的类可以不用实现 `Comparator` 接口，只需要保证方法签名和 `Comparator` 类中的 `compare()` 方法一致即可。

```java
Integer[] ints = {1, 2, 3, 4, 5, 6};
List<Integer> list = Arrays.asList(ints);

list.sort(new Comparator<Integer>() {
    @Override
    public int compare(Integer o1, Integer o2) {
        return o2 - o1;
    }
});
System.out.println(list);
```

##### 解释ArrayList扩容机制

当ArrayList中的元素数量达到当前容量时，ArrayList会进行扩容。扩容的过程大致如下：

**扩容计算：** 首先，ArrayList会计算一个新的容量。新的容量通常是原容量的1.5倍（即原容量加上原容量的一半）。但是，如果计算出的新容量小于当前所需的容量（例如，你一次性添加了大量的元素），那么新容量会被调整为当前所需的容量。

**数组复制：** 然后，ArrayList会创建一个新的数组，其大小为新计算出的容量。接着，它会将旧数组中的所有元素复制到这个新数组中。

**引用更新：** 最后，ArrayList内部的对象引用会从旧的数组切换到新的数组，这样ArrayList就可以使用新的更大的数组来存储元素。

```java
private void grow(int minCapacity) {
    // overflow-conscious code
    int oldCapacity = elementData.length;
    int newCapacity = oldCapacity + (oldCapacity >> 1);
    if (newCapacity - minCapacity < 0)
        newCapacity = minCapacity;
    if (newCapacity - MAX_ARRAY_SIZE > 0)
        newCapacity = hugeCapacity(minCapacity);
    // minCapacity is usually close to size, so this is a win:
    elementData = Arrays.copyOf(elementData, newCapacity);
}
```

##### 什么是 Set 集合？它与 List 有什么区别？

Set 集合是一种不允许重复元素的集合，而 List 允许重复。Set 是无序的，而 List 是有序的。

##### HashSet 和 TreeSet 之间有什么区别？

HashSet 是基于哈希表实现的，无序且不允许重复元素；TreeSet 是基于红黑树实现的，有序且不允许重复元素。

##### HashSet 和 HashMap 之间有什么联系？

HashSet 底层使用了 HashMap 来存储元素，只是将元素的值作为 HashMap 的键，值都是同一个对象。

```java
public boolean add(E e) {
    return map.put(e, PRESENT)==null;
}
```

##### 使用HashSet存储自定义对象时，可能会出现什么问题？应该怎么避免？

当使用HashSet存储自定义对象时，如果对象没有重写hashCode方法，那么计算出来的hashCode是基于对象的内存地址的哈希值。这意味着，即使两个对象的属性值相同，它们的hashCode也可能不同。

要想将自定义对象存入HashSet，需要正确的重写对象类的hashCode方法。

##### HashSet是否允许存入null值？

hashSet允许存入一个null值。

##### 什么是集合的无序性？

集合元素的无序性是指元素在集合中的顺序是不固定的，即元素的实际顺序不等同于元素插入集合中的顺序。

集合的有序性分为两种，一种是插入顺序有序，一种是元素顺序有序。前一种如ArrayList，LinkedList，这类集合对象会保存元素初始的插入顺序作为集合中元素的顺序。后一种如TreeSet，它的底层采用的是红黑树实现，在元素写入集合时会根据元素的值进行排序。

对于TreeSet类型，如果元素是一个自定义的对象，那么它的写入顺序分两种情况讨论。第一种情况是该对象实现了 `Comparable` 接口，此时TreeSet会使用接口的 `compareTo` 方法比较元素的值，并根据结果进行排序。第二种情况是该对象没有实现 `Comparable` 接口，这时候在创建TreeSet时需要手动提供一个自定义的比较器来实现元素排序，否则会抛出 `ClassCastException`。

```java
TreeSet<Person> treeSet = new TreeSet<>((o1, o2) -> {
    int age = o1.getAge() - o2.getAge();
    if (age < 0) {
        return -1;
    } else if (age == 0) {
        return 0;
    }
    return 1;
});
treeSet.add(new Person("zhangsan", 11));
treeSet.add(new Person("lisi", 12));
treeSet.forEach(e -> System.out.print(e + "   "));
```

#### 泛型

##### 什么是泛型？为什么要使用泛型？

泛型是一种参数化类型的机制，允许我们编写通用的代码，可以在运行时指定具体的类型。使用泛型可以提高代码的可读性、安全性和重用性。

##### 什么是泛型类和泛型方法？

* **泛型类** ：一个类可以使用泛型来定义其属性、方法或构造函数的参数类型。例如，`ArrayList<T>` 是一个泛型类，其中的 `T` 表示元素的类型。
* **泛型方法** ：一个方法可以使用泛型来定义其参数类型或返回值类型。例如，`public <T> T getFirst(List<T> list)` 是一个泛型方法，它返回列表中的第一个元素

##### 什么是类型擦除？

类型擦除是指在编译时擦除泛型类型信息，将泛型类型转换为原始类型。

1. **类型擦除** ：

* Java的泛型在编译期间会将所有的泛型信息擦除，替换为实际的类型。
* 在生成的字节码中，不包含泛型中的类型信息。
* 使用泛型时，编译器会在编译时去掉类型参数，这个过程称为类型擦除。
* 例如，定义 `List<Object>`和 `List<String>`等类型，在编译后都会变成 `List`，JVM看到的只是 `List`，而泛型附加的类型信息对JVM是不可见的。

1. **类型擦除后保留的原始类型** ：

* 原始类型是擦除泛型信息后，类型变量的真正类型。
* 无论何时定义一个泛型，相应的原始类型都会被自动提供，类型变量擦除，并使用其限定类型（无限定的变量用 `Object`）替换。
* 例如，`Pair<T>`中，如果 `T`是无限定的类型变量，那么用 `Object`替换，结果就是一个普通的类，类似于泛型加入Java语言之前的已经实现的样子。

1. **示例** ：

* 假设我们有一个泛型类 `Pair<T>`，如果 `T`是无限定的类型变量，那么原始类型就是 `Object`。
* 如果类型变量有限定，原始类型就用第一个边界的类型变量类替换。

**深入一些去了解：**

我们已经知道，在编译期间，编译器会执行类型擦除，`ArrayList<Integer>`变为了原始类型 `ArrayList`，并且它的元素类型被视为 `Object` 。但是这里需要注意一点，这里擦除的只是编码时传入的静态的元素类型，如这里的Integer，在实际运行过程中，传入的元素的实际类型是会被保留的。比如这里，在内存中呈现的依然是元素真实的类型Integer。

可以简单点理解，将泛型理解为一种开发期间编译器对开发人员的一种约束，它为开发人员在开发期间提供一种强类型检查机制，开发人员可以在编译期间检查到类型错误，而不必等待运行时才发现。

如下面的代码，结果返回为 `true` ，因为在实际内存中，元素的类型还是Integer。

```java
ArrayList<Integer> list = new ArrayList<>();
list.add(1);
System.out.println(list.get(0) instanceof Integer);
```

##### 什么是伪泛型？为什么java中的泛型是伪泛型？

伪泛型是指 Java 中的泛型机制在编译期间会将所有的泛型信息擦除，替换为实际的类型。尽管我们在源代码中使用了泛型，但在生成的字节码中，不包含泛型类型信息。因此，我们称之为“伪泛型”。

具体来说，以下是关于伪泛型的一些要点：

* **类型擦除** ：在编译期间，Java 编译器会将泛型信息擦除，将泛型类型转换为原始类型。这意味着在运行时，我们无法直接查看泛型的具体类型。
* **原始类型** ：原始类型是擦除泛型信息后，类型变量的真正类型。无论何时定义一个泛型，相应的原始类型都会被自动提供，类型变量擦除，并使用其限定类型（无限定的变量用 `Object`）替换。

虽然泛型在源代码中提供了类型安全性和抽象性，但在运行时，泛型的类型信息被擦除，只保留了原始类型。因此，我们称之为“伪泛型”。

Java 中的泛型是伪泛型，因为在运行时并没有实际的泛型类型信息，只有在编译时才会进行类型检查。

##### 什么是泛型的上下界通配符？起到什么作用？

* **上界通配符** （`<? extends T>`）：表示泛型参数必须是 `T` 或其子类。
* **下界通配符** （`<? super T>`）：表示泛型参数必须是 `T` 或其父类。

#### IO流

##### 字节流和字符流的区别是什么？

- **字节流**（InputStream/OutputStream）是用于处理原始二进制数据的流
- **字符流**（Reader/Writer）是用于处理字符数据的流。字符流在内部使用字节流来操作文件，但它还会使用合适的字符集来解码字节。

##### 在读取一个文件内容写入到另一个文件时怎么避免出现乱码？

在读取和写入文件时，乱码通常是由于字符编码不一致导致的。为了避免乱码，你需要确保在读取和写入文件时使用的字符编码是一致的。在Java中，可以使用 `InputStreamReader`和 `OutputStreamWriter`来指定字符编码。

```java
try (BufferedReader reader = new BufferedReader(new InputStreamReader(new FileInputStream("input.txt"), "UTF-8"));
     BufferedWriter writer = new BufferedWriter(new OutputStreamWriter(new FileOutputStream("output.txt"), "UTF-8"))) {
    String line;
    while ((line = reader.readLine()) != null) {
        writer.write(line);
        writer.newLine();
    }
} catch (IOException e) {
    e.printStackTrace();
}

```

除此之外，如果文件的编码格式未知或者为了最大程度地保持文件的原始字节序列，可以使用字节流来实现文件内容的复制，从而避免编码转换可能带来的问题。
在Java中，InputStream和OutputStream及其子类是用于处理字节数据的流。使用字节流可以保证读取和写入到文件系统中的数据是完全相同的字节序列，不会进行任何字符集的转换。这样可以确保文件在复制过程中保持其原始的字节内容，从而避免出现乱码问题。

##### 缓冲流是怎么提高IO操作性能的？

缓冲流（BufferedInputStream/BufferedOutputStream/BufferedReader/BufferedWriter）在内部维护一个缓冲区，当我们从流中读取或写入数据时，它会尽可能地一次读取或写入多个字节到缓冲区，这样可以减少实际的物理读写操作次数，从而提高IO操作的性能。

##### 什么是序列化和反序列化？有哪些第三方的序列化库？

- **序列化**是将对象的状态信息转换为可以存储或传输的形式的过程。
- **反序列化**则是将已序列化的数据恢复为对象的过程。

Java提供了 `java.io.Serializable`接口来支持序列化。同时，Java中也有许多第三方的序列化库，例如：

* **Google Gson** ：一个可以将Java对象转换为其JSON表示形式的库，也可以将JSON字符串转换回Java对象。
* **Jackson** ：一个可以读取和写入JSON和其他数据格式（如XML和CSV）的库。
* **Fastjson2** ：阿里巴巴的开源JSON处理库，可以将Java对象转换为JSON格式，也可以将JSON字符串转换为Java对象。

##### 什么是java中的文件锁？

文件锁是用于控制对文件的并发访问。

Java的 `java.nio.channels.FileLock`类提供了对文件的锁定和解锁操作。文件锁可以是共享的，也可以是独占的。共享锁只允许其他并发进程读取文件，但不允许写入。独占锁则不允许其他并发进程读取或写入文件。

```java
import java.io.RandomAccessFile;
import java.nio.channels.FileChannel;
import java.nio.channels.FileLock;

public class FileLockExample {
    public static void main(String[] args) {
        Thread t1 = new Thread(new Worker(), "Thread-1");
        Thread t2 = new Thread(new Worker(), "Thread-2");
        t1.start();
        t2.start();
    }

    static class Worker implements Runnable {
        @Override
        public void run() {
            try {
                RandomAccessFile file = new RandomAccessFile("test.txt", "rw");
                FileChannel fileChannel = file.getChannel();

                System.out.println(Thread.currentThread().getName() + " is waiting to acquire the lock...");
                FileLock lock = fileChannel.lock();
                System.out.println(Thread.currentThread().getName() + " has acquired the lock.");

                Thread.sleep(3000);

                lock.release();
                System.out.println(Thread.currentThread().getName() + " has released the lock.");

                fileChannel.close();
                file.close();
            } catch (Exception e) {
                e.printStackTrace();
            }
        }
    }
}

```

### 中级

#### JUC

##### CountDownLatch类的作用是什么？

`CountDownLatch`是一个同步工具类，它允许一个或多个线程等待直到在其他线程中执行的一组操作完成。

假设我们有一个应用程序，在启动之前需要初始化多个服务。我们想要在所有服务都初始化完成后才启动应用程序的主线程。我们可以使用 CountDownLatch 来实现这一点。

```java
import java.util.concurrent.CountDownLatch;

public class ApplicationLauncher {

    // 假设有三个服务需要初始化
    private static final int N = 3;

    public static void main(String[] args) {
        // 创建一个计数器，初始化为3
        CountDownLatch latch = new CountDownLatch(N);

        // 创建并启动三个服务初始化线程
        for (int i = 0; i < N; ++i) {
            new Thread(new ServiceInitializer(latch, "Service" + (i+1))).start();
        }

        // 主线程等待所有服务初始化完成
        try {
            latch.await(); // 阻塞，直到计数器降为0
        } catch (InterruptedException e) {
            e.printStackTrace();
        }

        // 所有服务都已初始化，主线程可以继续执行
        System.out.println("所有服务已初始化，应用程序正在启动...");
    }

    // 服务初始化任务
    static class ServiceInitializer implements Runnable {
        private final CountDownLatch latch;
        private final String serviceName;

        public ServiceInitializer(CountDownLatch latch, String serviceName) {
            this.latch = latch;
            this.serviceName = serviceName;
        }

        @Override
        public void run() {
            try {
                // 模拟服务初始化的耗时操作
                Thread.sleep((long) (Math.random() * 10000));
                System.out.println(serviceName + " 初始化完成。");
            } catch (InterruptedException e) {
                e.printStackTrace();
            } finally {
                // 完成初始化后，计数器减1
                latch.countDown();
            }
        }
    }
}

```

#### AQS

### 高级

#### JVM

#### 并发锁

##### 什么是分段锁？分段锁和同步锁有什么区别？

#### String

### Netty框架

### 通讯协议

#### http协议

#### socket协议

## JAVA Web

### jsp & servlet

### JavaScript

## 架构设计

### 设计模式

#### 六大原则

##### 单一职责原则

##### 里氏替换原则

##### 依赖倒置原则

##### 迪米特法则

##### 接口隔离原则

##### 开闭原则

#### 责任链模式

#### 单例模式

##### 双重检查锁实现

- 代码实现：

```java
public class Singleton {
    private volatile static Singleton uniqueSingleton;

    private Singleton() {
    }

    public Singleton getInstance() {
        if (null == uniqueSingleton) {
            synchronized (Singleton.class) {
                if (null == uniqueSingleton) {
                    uniqueSingleton = new Singleton();
                }
            }
        }
        return uniqueSingleton;
    }
}
```

- 说明：
  - volatile关键字是为了防止指令重排序。在虚拟机中，为一个对象分配内存空间可以分为3个步骤：分配内存空间、初始化对象、将对象指向分配的内存空间。但是在一些编译器中，为了优化性能，会对第二步和第三步进行重排序。此时可能出现引用指向一块内存区域之后，对象没有初始化成功。使用volatile关键字之后可以禁止指令重排序。
  - 双重检查锁的第一个if判断是为了提高代码性能，避免每次获取对象时都对请求加锁。
  - 第二个if判断是为了避免出现重复的对象实例。在多线程环境下，假设第一个线程执行完第一个if判断之后，在等待获取同步锁之前时间片结束，该线程并未获取到同步锁，此时第二个线程获取单例对象并成功创建对象实例。这里如果在同步代码内添加第二个if判断，那么等第一个线程获取到时间片之后，会成功获取同步锁并创建一个新的对象。而如果在同步锁代码块内添加第二个判断，那么第一个线程在进入代码块之后会再执行一次判断，避免重复创建对象。
- 缺陷：
  - 以上代码中，可以通过反序列化或者对象的克隆实现获取多个对象。
  - 以上代码中，可以通过反射的方式获取多个对象。

##### 枚举类实现

- 代码实现

```java
public enum Singleton {
    INSTANCE;

    public String doXX() {
        return "success";
    }

    public static void main(String[] args) {
        System.out.println(Singleton.INSTANCE.doXX());
    }
}
```

- 说明

在java中，枚举类的实例由JVM保证线程安全。

#### 工厂模式

#### 模板方法

### 设计方法

#### 线程池

参考[ThreadPool线程池](./后台技术/ThreadPoolExecutor线程池.md)

#### 分布式锁

#### 分布式事务

##### 两阶段提交

##### 三阶段提交

##### saga

##### seata

#### 缓存一致性

#### 接口幂等性

## 数据库

### SQL

#### 三范式

### MySQL

### Oracle

## Linux

### 基本操作

#### 文本处理

##### 查看命令

- less
- tail
- cat

##### 统计命令

- sort
- unlq

##### 文件编辑

- vim
- vi
- cat

##### 查找过滤

- grep
- awk
- diff
- find

#### 目录操作

##### 基本命令

- rm
  - 强制删除且不需要确认： `rm -rf ./xxx`
- cp
- mkdir
  - 一次创建多个目录： `mkdir -p a/ b/ c/`
- mv

##### 路径切换

- cd
  - 回到用户目录： `cd`
  - 回到上级目录： `cd -`
- ls
  - 按时间排序： `ls -lrt`
- pwd

#### 压缩、解压缩

- zip
  - 压缩： `zip -r a.zip ./a/*`
- unzip
  - 解压缩： `unzip -o a.zip`
- tar

### 资源管理

#### 服务管理

- service

#### 磁盘挂载

- mount

#### 权限配置

- chmod
- chown

### 系统状态

#### 系统资源

- top
- df
- free

#### 系统状态

- ps
- uname
- ifconfig
- ping
- netstat

### 容器化

#### docker

#### K8S

## Maven

### Maven依赖安装

maven安装jar包到本地maven仓库

```
mvn install:install-file 
-Dfile=d:/xxx-spring-boot-starter-2.x-9.5.1.jar 
-DgroupId=com.xxx.appserver 
-DartifactId=xxxxx-spring-boot-starter-9.5.1
-Dversion=9.5.1 
-Dpackaging=jar
```

## 缓存

### 本地缓存

#### ehcache

### Redis

#### 数据结构

**这部分代码由ai生成，没有经过测试**

##### string

字符串类型，可以存储一个字符串、整数或浮点数，主要用于存储简单的键值对。

- jedis操作代码

```java
import redis.clients.jedis.Jedis;

public class JedisStringExample {
    public static void main(String[] args) {
        Jedis jedis = new Jedis("localhost", 6379);
        jedis.set("key", "value");
        String value = jedis.get("key");
        System.out.println("Value: " + value);
        jedis.close();
    }
}

```

- springboot redistemplate操作代码

```java
import org.springframework.context.ApplicationContext;
import org.springframework.context.annotation.AnnotationConfigApplicationContext;
import org.springframework.data.redis.core.RedisTemplate;
import org.springframework.data.redis.core.StringRedisTemplate;

public class RedisTemplateStringExample {
    public static void main(String[] args) {
        ApplicationContext ctx = new AnnotationConfigApplicationContext(RedisConfig.class);
        StringRedisTemplate redisTemplate = ctx.getBean(StringRedisTemplate.class);
        redisTemplate.opsForValue().set("key", "value");
        String value = redisTemplate.opsForValue().get("key");
        System.out.println("Value: " + value);
    }
}

```

##### list

列表是简单的字符串列表，按照插入顺序排序。它允许从列表的头部或尾部添加或删除元素。list类型适合存储具有时序性的数据，可以用于实现一个简单的任务队列或者消息队列。

- jedis实现

```java
import redis.clients.jedis.Jedis;

public class JedisListExample {
    public static void main(String[] args) {
        Jedis jedis = new Jedis("localhost", 6379);
        jedis.lpush("list", "value1");
        jedis.lpush("list", "value2");
        String value = jedis.rpop("list");
        System.out.println("Value: " + value);
        jedis.close();
    }
}

```

- springboot redistemplate操作实现

```java
import org.springframework.context.ApplicationContext;
import org.springframework.context.annotation.AnnotationConfigApplicationContext;
import org.springframework.data.redis.core.ListOperations;
import org.springframework.data.redis.core.RedisTemplate;
import org.springframework.data.redis.core.StringRedisTemplate;

public class RedisTemplateListExample {
    public static void main(String[] args) {
        ApplicationContext ctx = new AnnotationConfigApplicationContext(RedisConfig.class);
        RedisTemplate<String, String> redisTemplate = ctx.getBean(RedisTemplate.class);
        ListOperations<String, String> listOps = redisTemplate.opsForList();
        listOps.leftPush("list", "value1");
        listOps.leftPush("list", "value2");
        String value = listOps.rightPop("list");
        System.out.println("Value: " + value);
    }
}

```

##### set

无序集合，采用哈希表实现，元素具有唯一性。可以用于存储需要去重的元素。

- 使用jedis实现操作

```java
import redis.clients.jedis.Jedis;

public class JedisSetExample {
    public static void main(String[] args) {
        Jedis jedis = new Jedis("localhost", 6379);
        jedis.sadd("set", "value1");
        jedis.sadd("set", "value2");
        Boolean isMember = jedis.sismember("set", "value1");
        System.out.println("Is member: " + isMember);
        jedis.close();
    }
}

```

- 使用springboot redistemplate实现操作

```java
import org.springframework.context.ApplicationContext;
import org.springframework.context.annotation.AnnotationConfigApplicationContext;
import org.springframework.data.redis.core.RedisTemplate;
import org.springframework.data.redis.core.SetOperations;

public class RedisTemplateSetExample {
    public static void main(String[] args) {
        ApplicationContext ctx = new AnnotationConfigApplicationContext(RedisConfig.class);
        RedisTemplate<String, String> redisTemplate = ctx.getBean(RedisTemplate.class);
        SetOperations<String, String> setOps = redisTemplate.opsForSet();
        setOps.add("set", "value1");
        setOps.add("set", "value2");
        Boolean isMember = setOps.isMember("set", "value1");
        System.out.println("Is member: " + isMember);
    }
}

```

##### hash

哈希是键值对结构的集合。适合存储对象，可以很方便的获取对象的信息。

- 使用jedis实现操作

```java
import redis.clients.jedis.Jedis;

public class JedisHashExample {
    public static void main(String[] args) {
        Jedis jedis = new Jedis("localhost", 6379);
        jedis.hset("hash", "field1", "value1");
        String value = jedis.hget("hash", "field1");
        System.out.println("Value: " + value);
        jedis.close();
    }
}

```

- 使用springboot redistemplate实现操作

```java
import org.springframework.context.ApplicationContext;
import org.springframework.context.annotation.AnnotationConfigApplicationContext;
import org.springframework.data.redis.core.HashOperations;
import org.springframework.data.redis.core.RedisTemplate;

public class RedisTemplateHashExample {
    public static void main(String[] args) {
        ApplicationContext ctx = new AnnotationConfigApplicationContext(RedisConfig.class);
        RedisTemplate<String, Object> redisTemplate = ctx.getBean(RedisTemplate.class);
  
        // 写入哈希表
        HashOperations<String, String, Object> hashOps = redisTemplate.opsForHash();
        hashOps.put("user:1", "name", "John Doe");
        hashOps.put("user:1", "age", 30);
  
        // 读取哈希表
        String name = (String) hashOps.get("user:1", "name");
        Integer age = (Integer) hashOps.get("user:1", "age");
  
        System.out.println("Name: " + name);
        System.out.println("Age: " + age);
  
        // 获取整个哈希表
        Map<String, Object> userMap = hashOps.entries("user:1");
        System.out.println(userMap);
    }
}

```

##### Zset

有序集合

- 使用jedis实现操作

```java
import redis.clients.jedis.Jedis;

public class JedisZSetExample {
    public static void main(String[] args) {
        Jedis jedis = new Jedis("localhost", 6379);
  
        // 写入有序集合
        jedis.zadd("leaderboard", 100, "Alice");
        jedis.zadd("leaderboard", 200, "Bob");
        jedis.zadd("leaderboard", 300, "Charlie");
  
        // 读取有序集合
        Set<String> members = jedis.zrange("leaderboard", 0, -1);
        System.out.println("Members: " + members);
  
        // 获取分数
        Double score = jedis.zscore("leaderboard", "Alice");
        System.out.println("Alice's score: " + score);
  
        jedis.close();
    }
}

```

- 使用springboot redistemplate实现操作

```java
import org.springframework.context.ApplicationContext;
import org.springframework.context.annotation.AnnotationConfigApplicationContext;
import org.springframework.data.redis.core.RedisTemplate;
import org.springframework.data.redis.core.ZSetOperations;

public class RedisTemplateZSetExample {
    public static void main(String[] args) {
        ApplicationContext ctx = new AnnotationConfigApplicationContext(RedisConfig.class);
        RedisTemplate<String, Object> redisTemplate = ctx.getBean(RedisTemplate.class);
  
        // 写入有序集合
        ZSetOperations<String, Object> zSetOps = redisTemplate.opsForZSet();
        zSetOps.add("leaderboard", "Alice", 100);
        zSetOps.add("leaderboard", "Bob", 200);
        zSetOps.add("leaderboard", "Charlie", 300);
  
        // 读取有序集合
        Set<Object> members = zSetOps.range("leaderboard", 0, -1);
        System.out.println("Members: " + members);
  
        // 获取分数
        Double score = zSetOps.score("leaderboard", "Alice");
        System.out.println("Alice's score: " + score);
    }
}

```

#### 数据持久化

redis数据持久化策略有 `AOF` 和 `RDB` 两种方案，其中 `AOF`为增量日志，`RDB`为全量内存快照。一般会使用两种方式一起实现redis数据持久化。

##### AOF

AOF (Append Only File) 是redis提供的一种增量形式的数据持久化形式，相对于RDB而言，操作更为轻量。在redis配置文件 `redis.conf` 中，默认开启了AOF，其配置为 `appendonly no`。同时，可以通过修改 `appendfilename` 来修改AOF文件保存的位置。

在不同的操作系统中，对于写数据的操作可能会有不同的处理方式。有些操作系统会立即将数据写入到磁盘上，而有些系统会先将数据写入到缓冲区，并在适当的时机将其写入到磁盘上。对于后一种实现，如果数据写入到缓冲区之后出现系统掉电关机，会导致缓冲区的数据丢失。对于以上情况，redis通过调用 `fsync()` 函数通知操作系统将数据写入到磁盘，保证数据安全。

在redis配置文件中，提供了三种fsync函数的调用策略：

- appendfsync no： 不执行fsync，由操作系统决定什么时候写入数据到磁盘。这种情况下速度最快，但是可能会存在数据丢失的风险。
- appendfsync always：在每次写入AOF日志后都执行fsync。这种情况速度最慢，但是可以保证数据安全。但是这种情况下会存在一些问题，加入系统正在执行大量的磁盘IO操作，这种情况下redis调用fsync可能会被长时间阻塞。
- appendfsync everysec：每秒执行一次fsync，这是一种折中的方案。这也是redis提供的默认的方案。


##### AOF自动重写功能

AOF文件记录的是redis数据库所有的更新和写入操作，在经过一段时间之后，可能在文件中的数据已经过期或者被删除了，此时这种数据记录在AOF文件中是没有意义的。而随着运行时间的推移，这种这种数据的操作记录是不可避免地会被写入到AOF文件中，导致AOF文件中记录了大量的无效的数据操作，对性能会产生影响。针对以上情况，redis提供了AOF文件重写功能用于优化和压缩AOF文件。

在redis中，提供了 `auto-aof-rewrite-percentage`和 `auto-aof-rewrite-min-size`两个参数用于控制AOF文件重写的触发大小。第一个参数是一个百分比的数值，第二个参数是一个文件大小数值。默认配置如下：

```shell
auto-aof-rewrite-percentage 100
auto-aof-rewrite-min-size 64mb
```

如上的配置中，当AOF文件的大小到达上次重写时文件大小的100%，且当前AOF文件大小大于64mb时，触发AOF重写。

在AOF重写过程中，假如说有大量新的操作触发AOF写入。这种情况下，在AOF重写期间会有大量的磁盘IO，可能会导致磁盘负载增大而产生延迟增加响应时间。为了解决这个问题，redis提供 `no-appendfsync-on-rewrite` 参数用于控制是否在AOF重写期间将AOF写入请求写入到磁盘中。当设置参数值为no时，AOF重写期间会继续将AOF写入请求写入到磁盘中，这种情况下可以有效地避免数据的丢失。当设置参数值为yes时，在AOF重写期间，新来的AOF请求会被保存在缓冲区，在等待AOF重写完成之后再被写入到磁盘，这种情况下可以有效地提高redis性能，但是可能存在部分数据丢失。

当redis运行过程中由于系统崩溃导致AOF文件被中途截断时，再次启动redis时，redis会根据 `aof-load-truncated` 参数决定如何处理AOF文件。当设置值为yes时，将加载被截断的 AOF 文件，并且 Redis 服务器开始发出日志以通知用户事件。否则，如果选项设置为 no，服务器将退出并显示错误，并拒绝启动。当选项设置为 no 时，用户需要使用 "redis-check-aof" 工具修复 AOF 文件然后重新启动服务器。

##### RDB

#### 数据淘汰策略

#### 实践设计

## 消息队列

### kafka

### RabbitMQ

### ActiveMQ

## Spring

## 微服务

## 实际问题

### 分布式集群下保证只有一个节点初始数据

### 上线后接口耗时偶发增大

### web中间件最大请求参数设置导致请求数据丢失问题

### nginx限制文件上传大小问题
